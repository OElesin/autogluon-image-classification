FROM nvidia/cuda:10.1-base-ubuntu16.04

# first layers should be dependency install so changes in code won't cause the build to
# start from scratch.
COPY requirements.txt /opt/program/requirements.txt

RUN apt-get update \
 && apt-get install -y --no-install-recommends \
    nginx \
    software-properties-common \
    build-essential \
    ca-certificates \
    libcudnn7=${CUDNN_VERSION} \
    cuda-command-line-tools-10-1 \
    cuda-cufft-10-1 \
    cuda-curand-10-1 \
    cuda-cusolver-10-1 \
    cuda-cusparse-10-1 \
    curl \
    git \
    libatlas-base-dev \
    libcurl4-openssl-dev \
    libnccl2=${NCCL_VERSION} \
    libgomp1 \
    libnccl-dev=${NCCL_VERSION} \
    libopencv-dev \
    openssh-client \
    openssh-server \
    vim \
    python3-dev \
    wget \
    zlib1g-dev \
    gcc \
 && apt-get clean \
 && rm -rf /var/lib/apt/lists/*
 && ln -s /usr/local/bin/pip3 /usr/bin/pip

RUN pip install --upgrade pip \
    && pip install --no-cache-dir -r /opt/program/requirements.txt

RUN pip install --upgrade mxnet-cu100 \
    && pip install autogluon

# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard
# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE
# keeps Python from writing the .pyc files which are unnecessary in this case. We also update
# PATH so that the train and serve programs are found when the container is invoked.

ENV PYTHONUNBUFFERED=TRUE \
    PYTHONDONTWRITEBYTECODE=TRUE \
    PATH="/opt/program:${PATH}" \
    MODEL_PATH="/opt/ml/model" \
    LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/lib" \
    DGLBACKEND=mxnet \
    CUDNN_VERSION=7.6.0.64-1+cuda10.1 \
    NCCL_VERSION=2.4.8-1+cuda10.1


# Set up the program in the image
COPY model /opt/program
WORKDIR /opt/program
#ENV SAGEMAKER_PROGRAM train
#ENV SAGEMAKER_PROGRAM serve

